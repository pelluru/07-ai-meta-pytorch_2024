
There are two ways to install n8n when self-hosting. Until you install it the right way for your needs, you may be limiting your automation abilities. Let's take a journey together through the key aspects of two workflows to help understand your n8n installation choices and get you setup for success. 

To self-host n8n, you can either use Docker or npm. I'll start with Docker. Docker is a great way to run applications since they stay self-contained and the update process is so easy. I'm on a Mac, so I have Docker for Desktop running. Some folks don't like Docker because they think they have to pay for it. Probably 90 to 95 percent of Docker users don't have to pay a penny to use it legally unless you are using it for work at a big company that brings in decent money who can easily pay the 5 bucks. I have spent a good amount of time with a number of the Docker alternatives but they all burn you after a while. I'll stick with pure Docker.  

So let's get n8n installed using docker compose. If you look online for a simple example, you'll hit our first problem. Every example is super complicated. It's local, we have one user, we don't need a complicated database setup or let's encrypt ssl certs. So in the github repo for this video, you'll find a good simple compose file. It specifies the image, a container name, ports, some environment info and a volume for persistence. Run `docker compose up -d` and we are set. Let's create a new owner account. We need a name, email, and password. And then you can create a workflow. 

So what is it going to be? I have done a few live streams on my channel. But sometimes they go on for 1 or 2 hours. When folks watch the recording, it's hard to pay attention without some sort of guidance. On YouTube you get that with chapter markers, but that means someone has to mark when each chapter starts. I want to do that automatically. So I need to send the transcript to an AI model and have that generate the chapters and markers. 

I could use the auto subtitles feature of Youtube and feed that to the model, but that takes an hour to show up sometimes. I want to download the video, convert it to audio, then use whisper to generate a transcription with times. Then hand that to an AI model to generate the table of contents. Whisper runs locally but will benefit from a GPU.  

I know n8n has a node that can execute a local command. let's try using that. I'll start with a manual trigger and then add that execute command node. This takes any command you would run at the command line. `pwd` shows us where we are right now on the filesystem. Click 'Test Step' and then look at the results. We see that the present working directory is /home/node. And we just hit our next problem.

Where is this? On my Mac, if I go into the home directory, there is nothing there. Definitely not a node directory. So let's run a different command in that node. `touch test123-thisisfromthevideo`. We just dropped a file in that directory. I have an idea of where it is but let's just confirm it. 

I'll run `docker exec -it n8n sh`. docker exec runs any command in a running docker container. The command we are running is 'sh' and the container is n8n. -it says to keep it open after the command runs. So now lets see where we are. So we can see we logged in to /home/node and there is our file that was created. So we are executing a command in the docker container. And now our last problem becomes another problem. 

Remember that the command I want to run is whisper and that needs to use the GPU. But Docker containers on Apple Silicon Macs have no access to the GPU. Maybe in the distant future some crazy person will create a linux driver for the apple silicon gpu, but that's not going to be soon. So this approach of running n8n in docker on my Mac isn't going to work for me. 

Luckily there is another way to install n8n. It's with npm. That's the package manager for NodeJS. So I can run `npm i -g n8n`. i for install and g for global. I still have that docker container running, so 'docker compose stop', and then run `n8n`. 

Let's try that workflow again. And this time for the command, I'll run `touch /tmp/test123`. And back on the mac, looking at the /tmp directory, there is test123. Perfect, our first simple workflow works. 

But what happens when we reboot this Mac. I reboot every 4 to 6 weeks and chances are when that happens I'm not going to remember to restart n8n or even how to do it. So we hit another problem. But this is easy to solve with a User Agent on the Mac. I use a program on the Mac called LaunchControl to edit the files.  

I create a new agent that launches n8n, but we quickly hit another problem. It turns out User Agents don't have access to the local environment set in your shell profiles. So we need to set everything in the User Agent plist. Easy enough to solve and with this we can try starting the agent again and n8n is up and running. And even better, it will be running as soon as we boot up again. 

Let's move on to the next workflow. I like to read news items and then share the interesting stuff on twitter. Another interesting node in n8n has the ability to trigger a workflow when something hits a webhook. If I find a news article on my mac, this is no problem. But how about when I find one on my phone? When I am out and about, my phone isn't on the same network as my mac, so I have hit another problem. I could poke a hole in my network and port forward to let me access the port remotely. But then so can everyone. That's a big security risk. I can use something like cloudflare's tunnels, but they are sometimes fickle and drop connections. And how about the times when my Mac is in my backpack powered off? Now no workflows can run. I can solve this problem by moving into the cloud. 

But I mentioned needing a GPU. So I can find a cloud instance with a decent gpu and spin that up. And before solving the last problem, we have another problem. This is the listing on Brev.dev, one of my favorite places to go for cloud instances with GPUs. Most other places make you configure something then wait a few minutes only to get an error that there was no availability in that region, and I never get that with Brev. I can see they start around 50 cents an hour to 5 dollars an hour and even more than that. There are 720 hours in a 30 day month. Even for the cheapest GPU, we are looking at 360 dollars a month. And the GPU in my mac is much more powerful. 

But this problem can be solved by changing the requirements, even the ones we haven't said aloud. There is no reason we can't run two instances of n8n. One for local GPU tasks, and another for everything else. And so we can spin up a cheap instance on Digital Ocean or whoever is your favorite host. I already have one I am using for other things on Digital Ocean. It's a 12 dollar a month instance and has plenty of room. I spend an extra couple bucks on top of that for regular backups. 

At this point you might be thinking I am way too excited by Digital Ocean, and Brev.dev, and n8n, and Docker and others. So one of them, or all of them, must be paying me to sponsor this video. No. This is not sponsored. No one is paying me at the time of making this video or publishing it. I just really like these products and they are part of my daily workflows. That said, n8n did reach out to me a couple months ago to see if a  sponsorship would work. But since then they have been mostly radio silent, despite dozens of emails from me. That said, n8n, you have my email if you want to continue that conversation. And you, the viewer can also help me out. How about clicking the like button and subscribing to the channel. It helps out immensely and I just hit another subscriber milestone this morning. 

I have Searxng and NocoDB running in Docker on that Digital Ocean Droplet so I'll use Docker for n8n as well. I have to complicate things in that docker compose file a little bit though. I have a nice short domain name and want to access n8n by using the name n.mydomainname. To do that with the others I use traefik. Traefik can be a bit of a pain to configure, but I just did what Techno Tim told me to do and everything has worked. I suggest you watch that video to get started. 

Then I can use this docker compose file to get n8n running. Notice that I am still not using a regular database but I have added some additional environment variables and some labels so that traefik will reverse proxy my setup. Then add n.mydomainname to my dns provider. And everything is set. 

Normally to update a container, all you have to do is stop the container, remove it, pull the image, and restart the container. As long as the data and config is saved to a volume this works really well. And since it is the same process for every container, we can automate it. I use watchtower running every few hours to do exactly that, keeping n8n and searxng and nocodb always up to date. It's a terrible idea to use that for production workloads in a company, but amazing for a homelabber. 

So now I can create a new workflow that does something when I hit a webhook. So click the plus sign and add that node. Right away we see the url for a test event that we can play with. I'll copy that url and then on my iPhone create a shortcut that opens a web address, pasting in that address. Now in n8n, click 'listen for test event' and back on the phone run that shortcut. And boom, we see that it worked. So now I can build out that flow,  and the shortcut and have something working. 

Now we have two instances of n8n, and have solved all the problems that have come up, but there is a new problem that may not be entirely obvious. In one of my workflows, my cloud instance starts a flow and then it needs something done in an AI model. There are some things I use a hosted model for and for that the best I have found is Claude. But since in so many cases, locally run AI models are just as good and sometimes better... and free since I already have the computer, I wait for that host to be available and let it trigger a new workflow there. There are a few ways to get that to happen. 

The first thing I did was to write a row to a database, and then have the instance on my mac check the database every minute for something new. Then that would trigger the flow. Pushcut also would allow this to happen, but I think I have to pay for that. Then recently I have started to use Telegram to send and receive those messages between these two machines. And it works really well. The downside is that its super cryptic to get configured and running. maybe I'll make a video about that in the future. 

But now we have a good setup that solves all of my needs going forward. I can run workflows on demand and get the benefit of using a local GPU. I love it and it's been working super well. Are you using n8n? How did you install it? I would love to learn more about your setup in the comments below. Thanks so much for watching. Goodbye. 


